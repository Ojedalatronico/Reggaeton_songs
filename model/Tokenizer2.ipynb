{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a03913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"letrasfinal.txt\", \"r\") as f:\n",
    "    text=f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1adfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sweetviz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import sweetviz as sw\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c829dee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_text=text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf81f914",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "def tokeni()\n",
    "    tokenizer=keras.preprocessing.text.Tokenizer(char_level=True)\n",
    "    tokenizer.fit_on_texts(shakespeare_text)\n",
    "\n",
    "    max_id=len(tokenizer.word_index)\n",
    "    dataset_size=tokenizer.document_count\n",
    "    [encoded]=np.array(tokenizer.texts_to_sequences([shakespeare_text]))-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e339830",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8950ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_id=len(tokenizer.word_index)\n",
    "dataset_size=tokenizer.document_count\n",
    "[encoded]=np.array(tokenizer.texts_to_sequences([shakespeare_text]))-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdde0108",
   "metadata": {},
   "outputs": [],
   "source": [
    "[encoded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f23ed3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 12:36:46.262781: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-10 12:36:46.263302: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'load_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m         text\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39mnext_char(text,temperature)\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\n\u001b[0;32m---> 31\u001b[0m model\u001b[38;5;241m=\u001b[39m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExample2.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'load_model'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "with open(\"letrasfinal.txt\", \"r\") as f:\n",
    "    text=f.read()\n",
    "tokenizer=keras.preprocessing.text.Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(text)\n",
    "\n",
    "max_id=len(tokenizer.word_index)\n",
    "dataset_size=tokenizer.document_count\n",
    "[encoded]=np.array(tokenizer.texts_to_sequences([text]))-1\n",
    "\n",
    "model=tf.load_model(\"Example2.h5\")\n",
    "\n",
    "def preprocess(texts):\n",
    "    X=np.array(tokenizer.texts_to_sequences(texts))-1\n",
    "    return tf.one_hot(X,max_id)\n",
    " \n",
    "def next_char(text,temperature=1):\n",
    "    X_new=preprocess([text])\n",
    "    y_proba=model.predict(X_new)[0,-1:,:]\n",
    "    rescaled_logits=tf.math.log(y_proba)/temperature\n",
    "    char_id=tf.random.categorical(rescaled_logits,num_samples=1)+1\n",
    "    return tokenizer.sequences_to_texts(char_id.numpy())[0]\n",
    " \n",
    "def complete_text(text,n_chars=100,temperature=1):\n",
    "    for _ in range(n_chars):\n",
    "        text+=next_char(text,temperature)\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ea584f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 12:39:19.899506: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-03-10 12:39:19.900863: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-10 12:39:19.900948: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Portatil-Jesus): /proc/driver/nvidia/version does not exist\n",
      "2022-03-10 12:39:19.909414: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model=keras.models.load_model(\"Example2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcf61ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maria\n",
      "que dem√°s\n",
      "quy, de cuerpo sientes\n",
      "dale saber\n",
      "me cankee\n",
      "mambe!)\n",
      "quisierates lama\n",
      "al si sabar\n",
      "jundo ch\n"
     ]
    }
   ],
   "source": [
    "print(complete_text(\"maria\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
